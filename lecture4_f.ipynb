{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文档信息的向量化\n",
    "\n",
    "所谓文档信息的向量化，就是将文档信息***数值化*** ，从而便于进行建模分析。\n",
    "\n",
    "### 词袋模型(One-hot表示方式)\n",
    "\n",
    "* 几乎是最早的用于提取文本特征的方法\n",
    "* 将文本直接简化为一系列词的集合\n",
    "  * 不考虑其语法和词序关系，每个词都是独立的 \n",
    "* 举例：\n",
    "  1. 对语料进行清理，并完成分词\n",
    "    * 大鱼/吃/小鱼/也/吃/虾米，小鱼吃虾米。\n",
    "  2. 对每个词进行编号，形成字典（顺序无关的流水号即可）\n",
    "    * {\"大鱼\":1,\"吃\":2,\"小鱼\":3,\"也\":4,\"虾米\"：5}\n",
    "  3. 用0/1代表该词是否在文本中出现，从而将文本记录为一个特征向量\n",
    "    * 大鱼吃小鱼也吃虾米 ->\\[大鱼,吃,小鱼,也,虾米\\]->\\[1,2,1,1,1\\]\n",
    "    * 小鱼吃虾米 ->\\[小鱼,吃,虾米\\]->\\[0,1,1,0,1\\]\n",
    "* 该方式也被称为词袋模型，Bag of Words，BOW\n",
    "  * 词和文本的关联就相当于文本是一个袋子，词只是直接装在袋子里\n",
    "* 显然，词袋模型是比较简单的模型，对文本中的信息有较多丢失，但已经可以解决很多实际问题\n",
    "  * 词袋模型的提出最初是为了解决文档分类问题，目前主要应用在NLP(Natural Language Process)，IR(Information Retrival)，CV(Computer Vision)等领域\n",
    "* 也可以不考虑词频，减少模型复杂度\n",
    "  * 词集模型：Set Of Words，单词构成的集合，常见于短文本分析\n",
    "  * 大鱼吃小鱼也吃虾米 ->\\[大鱼,吃,小鱼,也,虾米\\]->\\[1,**1**,1,1,1\\]\n",
    "* 优点：\n",
    "  * 解决了分类器不好处理离散数据的问题\n",
    "  * 在一定程度上也起到了扩充特征的作用\n",
    "* 缺点：\n",
    "  * 不考虑词与词之间的顺序\n",
    "  * 它假设词与词之间相互独立（在大多数情况下，词与词是相互有关联的）\n",
    "    * 老公 vs 老婆，老婆 vs 孩子他妈\n",
    "  * 它得到的特征是离散稀疏的（维度灾难）\n",
    "    * 每个词都是茫茫\"0\"海中的一个1：\\[0 0 0 0 0 **1** 0 0 0 0 0 0 ...\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 词袋模型的gensim实现\n",
    "\n",
    "***gensim的安装***\n",
    "\n",
    "> pip install gensim\n",
    "> \n",
    "> 或者\n",
    "> \n",
    "> conda install gensim\n",
    "\n",
    "安装完成后如果使用word2vec时报错，建议去gensim官网下载MS windows install的exe程序进行安装：\n",
    "\n",
    "[https://pypi.python.org/pypi/gensim](https://pypi.python.org/pypi/gensim)\n",
    "\n",
    "***建立字典***\n",
    "\n",
    "Dictionary类用于建立word<->id映射关系，把所有单词取一个set()，并对set中每个单词分配一个Id号的map\n",
    "\n",
    "> class gensim.corpora.dictionary.Dictionary(\n",
    "> \n",
    "> documents=None : 若干个被拆成单词集合的文档的集合，一般以list in list形式出现\n",
    "> prune_at=2000000 : 字典中的最大词条容量\n",
    "> )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "\n",
    "texts = [['human', 'interface', 'computer']]\n",
    "dct = Dictionary(texts)  # fit dictionary\n",
    "dct.num_nnz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Dictionary类的属性***\n",
    "\n",
    "> token2id\n",
    "> \n",
    "> dict of (str, int) – token -> tokenId.\n",
    "> \n",
    "> id2token\n",
    "> \n",
    "> dict of (int, str) – Reverse mapping for token2id, initialized in lazy manner to > save memory.\n",
    "> \n",
    "> dfs\n",
    "> \n",
    "> dict of (int, int) – Document frequencies: token_id -> in how many documents > > > contain this token.\n",
    "> \n",
    "> num_docs\n",
    "> \n",
    "> int – Number of documents processed.\n",
    "> \n",
    "> num_pos\n",
    "> \n",
    "> int – Total number of corpus positions (number of processed words).\n",
    "> \n",
    "> num_nnz\n",
    "> \n",
    "> int – Total number of non-zeroes in the BOW matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'computer': 0,\n",
       " 'human': 1,\n",
       " 'interface': 2,\n",
       " 'cat': 3,\n",
       " 'meow': 4,\n",
       " 'say': 5,\n",
       " 'dog': 6}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 向字典增加词条\n",
    "dct.add_documents([[\"cat\", \"say\", \"meow\"], [\"dog\"]])  \n",
    "dct.token2id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "转换为BOW稀疏向量\n",
    "\n",
    "> dct.doc2bow( # 转换为BOW格式：list of (token_id, token_count)\n",
    "> \n",
    "> document : 用于转换的词条list\n",
    "> allow_update = False : 是否直接更新所用字典\n",
    "> return_missing = False : 是否返回新出现的（不在字典中的）词\n",
    "> )\n",
    "\n",
    "输出结果\n",
    "\n",
    "[(0, 2), (1, 2)]，表明在文档中id为0,1的词汇各出现了2次，至于其他词汇则没有出现\n",
    "return_missing = True时，输出list of (int, int), dict of (str, int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 1), (6, 1)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct.doc2bow([\"this\", \"is\", \"cat\", \"not\", \"a\", \"dog\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(3, 1), (6, 1)], {'a': 1, 'is': 1, 'not': 1, 'this': 1})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct.doc2bow([\"this\", \"is\", \"cat\", \"not\", \"a\", \"dog\"], return_missing = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***转换为BOW长向量***\n",
    "可考虑的思路：\n",
    "\n",
    "    从稀疏格式自行转换。\n",
    "    直接生成文档-词条矩阵。\n",
    "\n",
    "doc2idx( # 转换为list of token_id\n",
    "\n",
    "    document : 用于转换的词条list\n",
    "    unknown_word_index = -1 : 为不在字典中的词条准备的代码\n",
    "\n",
    "输出结果\n",
    "\n",
    "    按照输入list的顺序列出所出现的各词条ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1, -1, -1, 6, -1, 3]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct.doc2idx([\"this\", \"is\", \"a\", \"dog\", \"not\", \"cat\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实战：生成词向量\n",
    "尝试编制以下程序：\n",
    "\n",
    "    以段为单位依次读入射雕第一回的内容。\n",
    "    为每一段分别生成bow稀疏向量。\n",
    "    生成稀疏向量的同时动态更新字典。\n",
    "\n",
    "请自行编制bow稀疏向量和标准长向量互相转换的程序。\n",
    "\n",
    "在文档词条矩阵中可以看到许多类似“黄蓉道”、“黄蓉说”之类的词条，请思考对此有哪些处理办法。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
